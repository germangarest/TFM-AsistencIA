{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewgg2XCA98e-"
      },
      "source": [
        "# Modelo de Deep Learning para la deteccion de fuego(s)\n",
        "\n",
        "## Modelo basado en redes neuronales convolucionales (CNN) que sigue el paradigma de la visión artificial (Computer Vision) para detectar fuegos en imagenes (fotos, videos)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importo las librerías y dependencias necesarias\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import pathlib\n",
        "import zipfile\n",
        "import requests\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import zipfile\n",
        "import gdown\n",
        "import shutil\n",
        "import cv2"
      ],
      "metadata": {
        "id": "7S101KX1azu5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Me conecto a mi Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ASbbgmeb3n9",
        "outputId": "3fe2bf08-b4fe-48cd-9f91-50e752648700"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para descargar el dataset\n",
        "\n",
        "def download_dataset():\n",
        "    \"\"\"\n",
        "    Descargo y organizo el dataset de Fire Detection from Images desde Google Drive\n",
        "    \"\"\"\n",
        "    dataset_url = \"https://drive.google.com/file/d/11UaWR7d8GX43G7ANfPz_CAk80tNQsDF6/view?usp=sharing\"\n",
        "    data_dir = pathlib.Path(\"fire_detection_dataset\")\n",
        "\n",
        "    if not data_dir.exists():\n",
        "        print(\"Descargando dataset...\")\n",
        "        data_dir.mkdir(parents=True, exist_ok=True)\n",
        "        zip_path = data_dir / \"fire_dataset.zip\"\n",
        "        gdown.download(url=dataset_url, output=str(zip_path), quiet=False, fuzzy=True)\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(data_dir)\n",
        "        zip_path.unlink()\n",
        "        source_dir = data_dir / \"fire_dataset\"\n",
        "        if source_dir.exists():\n",
        "            for item in source_dir.iterdir():\n",
        "                if item.is_dir():\n",
        "                    dest_path = data_dir / item.name\n",
        "                    if dest_path.exists():\n",
        "                        shutil.rmtree(dest_path)\n",
        "                    shutil.move(str(item), str(data_dir))\n",
        "            shutil.rmtree(str(source_dir))\n",
        "\n",
        "    return data_dir\n"
      ],
      "metadata": {
        "id": "eiVH75Isa6-A"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para crear el modelo usando redes neuronales convolucionales (CNN)\n",
        "\n",
        "def create_model():\n",
        "    \"\"\"\n",
        "    Creo un modelo CNN usando la API secuencial de Keras\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "fhYEJfoAbCGQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para preparar los datos\n",
        "\n",
        "def prepare_data(data_dir, batch_size=32):\n",
        "    \"\"\"\n",
        "    Preparo los generadores de datos para entrenamiento y validación\n",
        "    \"\"\"\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        str(data_dir), target_size=(224, 224), batch_size=batch_size,\n",
        "        class_mode='binary', subset='training', classes=['fire_images', 'non_fire_images']\n",
        "    )\n",
        "    validation_generator = train_datagen.flow_from_directory(\n",
        "        str(data_dir), target_size=(224, 224), batch_size=batch_size,\n",
        "        class_mode='binary', subset='validation', classes=['fire_images', 'non_fire_images']\n",
        "    )\n",
        "    return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "6t2LFxMabKdm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para entrenar el modelo\n",
        "\n",
        "def train_model(model, train_generator, validation_generator, epochs=20):\n",
        "    \"\"\"\n",
        "    Entreno el modelo y guardo el mejor modelo en formato HDF5\n",
        "    \"\"\"\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        'fire_detection_model.h5', monitor='val_accuracy', save_best_only=True, mode='max'\n",
        "    )\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator,\n",
        "                        callbacks=[checkpoint, early_stopping])\n",
        "    model.save('fire_detection_model.h5')\n",
        "    return history"
      ],
      "metadata": {
        "id": "tj1u2t-rbT4O"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para extraer los frames\n",
        "\n",
        "def extract_frames(video_path, output_folder, frame_rate=5):\n",
        "    \"\"\"\n",
        "    Extrae frames de un video cada 'frame_rate' fotogramas y los guarda en formato PNG en la carpeta especificada.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if count % frame_rate == 0:\n",
        "            frame_filename = os.path.join(output_folder, f\"frame_{count}.png\")\n",
        "            cv2.imwrite(frame_filename, frame)\n",
        "        count += 1\n",
        "    cap.release()\n",
        "    print(f\"Frames guardados en {output_folder}\")"
      ],
      "metadata": {
        "id": "5Iez8n58bZFv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para ejecutar el modelo\n",
        "\n",
        "def main():\n",
        "    shutil.rmtree(\"fire_detection_dataset\", ignore_errors=True)\n",
        "    data_dir = download_dataset()\n",
        "    batch_size, epochs = 32, 5\n",
        "    model = create_model()\n",
        "    train_generator, validation_generator = prepare_data(data_dir, batch_size)\n",
        "    print(\"Iniciando entrenamiento...\")\n",
        "    history = train_model(model, train_generator, validation_generator, epochs)\n",
        "    model.save('fire_detection_model.h5')\n",
        "    print(\"Modelo guardado como 'fire_detection_model.h5'\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Sne3YxRTbg0p"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargo el modelo h5 en local\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Descargar el archivo .h5\n",
        "files.download('fire_detection_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VPp9XEQOjmFI",
        "outputId": "658777d4-89e3-472e-fa34-fada2e89569f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_12eaa33f-0187-498b-b7cb-7f359c28d189\", \"fire_detection_model.h5\", 231225072)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EJemplo de uso\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "video_path = \"/content/drive/MyDrive/Dataframes/Noria.mp4\"\n",
        "output_folder = \"/content/frames/\"\n",
        "extract_frames(video_path, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvPBFLgAbna-",
        "outputId": "cd16465f-7374-4c9f-d7ac-672e6bb5b26e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=11UaWR7d8GX43G7ANfPz_CAk80tNQsDF6\n",
            "From (redirected): https://drive.google.com/uc?id=11UaWR7d8GX43G7ANfPz_CAk80tNQsDF6&confirm=t&uuid=be32210b-e99b-428d-b67d-0eca183f454f\n",
            "To: /content/fire_detection_dataset/fire_dataset.zip\n",
            "100%|██████████| 406M/406M [00:09<00:00, 45.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 images belonging to 2 classes.\n",
            "Found 199 images belonging to 2 classes.\n",
            "Iniciando entrenamiento...\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7994 - loss: 0.4788"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 7s/step - accuracy: 0.8019 - loss: 0.4732 - val_accuracy: 0.8543 - val_loss: 0.3044\n",
            "Epoch 2/5\n",
            "\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.9169 - loss: 0.1943"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}